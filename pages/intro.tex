%#! platex main.tex

%======================================================================
\chapter{はじめに}
\label{cha:intro}

近年, 食事管理アプリにより, 食事の写真から食品やカロリなどの栄養素を自動で記録できるようになってきた. これらの技術は, 食事の写真から画像認識技術により, 食品を特定し, 栄養データを算出することがベースとなっている. 例えば, カロミル\footnote{健康管理アプリ、カロミルとは？｜食事内容・日々の体重・運動量をアプリで簡単に記録~\url{https://www.calomeal.com/}}は, iOS・Androidアプリとして提供されており, スマートフォンのカメラで食事の写真を撮るだけで, 食事の内容を解析し, 自動で摂取栄養素を記録することができる.

一方で, 健康的な食事を行う上で, 摂取栄養素だけでなく食べる順番やスピードを意識することは非常に重要である. 日本の学校教育では, 米やパンなどといった主食と, 汁物や飲料, おかずを順序よく食べる方法「三角食べ」を推奨していた. 学術面においても, 食べる順番に重点をおいた食事指導の有効性については関西電力医学研究所の研究グループにより証明されており, 最初の5分間は食物繊維を含む食品やタンパク質や脂質を含む食品を食べ, その後, 炭水化物を含む食品を, 食物繊維を含む食品やタンパク質や脂質を含む食品と一緒に食べるよう指導すると, 体重の減量に影響を与えることを報告した\cite{yabe2019107450}. さらに, 糖尿病予防にも効果があり, 野菜から先に摂取すると, 米飯から先に摂取した場合と比較して食後の血糖値の上昇を抑えることができる\cite{tonyobyo53112}. また, 食べる速度についても, 早食いは肥満や糖尿病, 心臓に対して悪影響を及ぼすことが明らかになっている\cite{20249}\cite{beyond_willpower}. 以上の事実から, 一品ずつ集中して食べる「ばっかり食べ」や咀嚼をあまり行わない「早食い」をする子供に対して注意することは妥当であると言える.

\begin{figure}[t]
  \begin{center}
    \includegraphics[clip, width=1.0\hsize]{img/system.png}
    \caption{食事中の音から食事行動をフィードバックするシステム}
    \label{fig:system}
  \end{center}
\end{figure}

食べる順番や速度などを含む食事行動の記録やフィードバックに着目した研究やプロダクトも存在する. シャープが開発したbitescan\footnote{咀嚼計「bitescan（バイトスキャン）」：シャープ~\url{https://jp.sharp/business/bitescan/}}では, 独自の耳掛け式のウェアラブルデバイスを用いて, 食事中にリアルタイムで咀嚼検出を行うことで, 咀嚼テンポや食事の時間などを記録し, フィードバックすることができる. しかし, 独自のウェアラブルデバイスが必要となるため, 普及性の観点で課題があり, そもそも咀嚼回数のみを計測しているため, 食べる順番を記録することができない. また, ウェアラブルデバイスで食事行動を撮影した一人称映像から食事内容をリアルタイムで検出する研究も存在するが, この手法も食事中にカメラで撮影し続ける必要があるため, 一般的な食事シーンで計測を行うのは受け入れ難い\cite{10.1145/3551626.3564964}.

\begin{figure}[t]
  \begin{center}
    \includegraphics[clip, width=1.0\hsize]{img/eat2pic-concept.png}
    \caption{eat2picのコンセプト}
    \label{fig:eat2pic-concept}
  \end{center}
\end{figure}

我々の研究グループでは, 健康的な食生活を促進する行動変容支援システムとしてeat2picを提案している\cite{10.1145/3580784}. eat2picは図\ref{fig:eat2pic-concept}に示すように, 物理世界における「食べる」行動をモニタリングし, それをデジタルな「描く」世界に反映させるナッジングシステムである. 独自の箸型センサを用いて一口ずつ何をどのくらいの速度で食べたかを自動で追跡し, 食事行動の良し悪しを絵画で表現することで, リアルタイムの視覚的フィードバックを提供している. しかし, eat2picのセンシングアプローチはカメラとIMUを搭載した専用の箸型センサを使用する必要があるため, 日常生活での利便性や社会全体への普及可能性という観点で, 課題が残っている. また, 既存のeat2picシステムは食材を噛むという動作に応じて絵を描くというインタラクションは未対応となっている. eat2picが噛む動作に対応することができれば, 絵を用いた介入によって, よく噛んで食べるといった健康的な食事行動を誘引できる可能性が広がる.

本研究では, すでに普及している市販のイヤラブルデバイスとスマートフォンのみを使用し, 食品推定と咀嚼検出が可能なセンシング手法を提案する. さらに, 本研究が提案するセンシング手法を用いた食事行動のフィードバックシステム（図\ref{fig:system}）の一例として, eat2picのナッジメカニズムをベースに, 「噛む」動作に応じてデジタルな「描く」世界に反映させる「Chew-Draw」という新たなインタラクションを提案する.

本稿では, 食事中に発生する音を収集し, 収集したデータを分析し, 食品認識と咀嚼検出を行う手法を提案する. まず, 食事中の音や咀嚼回数を計測することに特化した独自のアプリケーションを新たに開発し, このアプリケーションを用いて分析のためのデータ収集実験を行なった. データ収集実験では, 17名の被験者を対象にアプリケーションを配布し, ワイヤレスイヤホンを装着した状態で1品ずつ食事を行なった. また, 咀嚼検出の分析のために, 実験中に咀嚼回数を被験者自身にカウントしてもらうように指示した. 食品認識の手法については, 計測した食事中の音をメルスペクトログラムに変換し, 畳み込みニューラルネットワークで学習させ, 食品推定モデルを作成する. 咀嚼検出については, 食事中の音から振幅に基づくピーク検出を行うことで咀嚼の検出を行う. 16種類の食品を対象にデータ収集実験を行なった結果, 合計で13422秒の音データを得ることができ, このデータを用いて食品推定モデルを学習させたところ, 検証用の音データに対して, 精度$77.5\%$で食事内容を推定できることを確認した. また, 10秒間の音データに対して被験者がカウントした咀嚼回数とピーク検出回数との間の平均絶対値誤差$MAE$を算出したところ, $MAE = 4.9$を確認することができた. さらに「Chew-Draw」インタラクションを実現するために, リアルタイムで食品認識と咀嚼検出を行い, その結果をデジタルキャンバスに反映させるスマートフォン向けのアプリケーションを提案する.

本稿の構成は以下の通りである.
第2章で食品推定・咀嚼検出・イヤラブルデバイスを用いた人間活動認識（HAR）に関する関連研究について述べる. 第3章でデータ収集アプリケーションの設計・開発について述べ，第4章で食事中の音から食品認識・咀嚼検出を行う手法について述べる. 第5章で評価実験について述べ，第6章で食事行動のフィードバックシステムの提案について述べる. 最後に第7章で本稿の結論および今後の課題について述べる.

%%% Local Variables:
%%% mode: yatex
%%% TeX-master: "main"
%%% End:
